{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LASWlGJFyNWZ",
        "outputId": "2e3902bf-db65-4959-e060-7a3a5b1d16a9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "import os\n",
        "import glob\n",
        "import pickle\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "import matplotlib.pyplot as plt\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "data_directory = \"/content/drive/MyDrive/data\"\n",
        "\n",
        "game_to_label = {\"pinpong\": 0, \"carracingv3\": 1, \"airraid\": 2}\n",
        "pkl_files = glob.glob(os.path.join(data_directory, \"*.pkl\"))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "class LazyGameDataset(Dataset):\n",
        "    def __init__(self, pkl_files, game_to_label):\n",
        "        self.index = []\n",
        "        self.pkl_files = pkl_files\n",
        "        self.game_to_label = game_to_label\n",
        "        print(\"Building index for lazy dataset...\")\n",
        "        for file in pkl_files:\n",
        "            game_name = os.path.basename(file).split('.')[0]\n",
        "            label = game_to_label[game_name]\n",
        "            print(f\"Indexing file: {file}\")\n",
        "            with open(file, \"rb\") as f:\n",
        "                rollouts = pickle.load(f)\n",
        "            for ep_idx, episode in enumerate(rollouts):\n",
        "                for trans_idx, transition in enumerate(episode):\n",
        "                    self.index.append((file, ep_idx, trans_idx, label))\n",
        "        print(f\"Total samples indexed: {len(self.index)}\")\n",
        "        self.current_file = None\n",
        "        self.current_data = None\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.index)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        file, ep_idx, trans_idx, label = self.index[idx]\n",
        "        if file != self.current_file:\n",
        "            with open(file, \"rb\") as f:\n",
        "                self.current_data = pickle.load(f)\n",
        "            self.current_file = file\n",
        "        rollouts = self.current_data\n",
        "        episode = rollouts[ep_idx]\n",
        "        transition = episode[trans_idx]\n",
        "        obs, action, reward, next_obs, done = transition\n",
        "        obs = np.array(obs)\n",
        "        obs = np.transpose(obs, (2, 0, 1))\n",
        "        obs = torch.tensor(obs, dtype=torch.float32)\n",
        "        label = torch.tensor(label, dtype=torch.long)\n",
        "        return obs, label"
      ],
      "metadata": {
        "id": "KPoA2rBeyRtb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = LazyGameDataset(pkl_files, game_to_label)\n",
        "batch_size = 32\n",
        "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True, num_workers=0)\n",
        "\n",
        "selected_indices = {}\n",
        "for i, (_, _, _, label) in enumerate(dataset.index):\n",
        "    if label not in selected_indices:\n",
        "        selected_indices[label] = i\n",
        "    if len(selected_indices) == len(game_to_label):\n",
        "        break\n",
        "selected_indices = [selected_indices[i] for i in range(len(game_to_label))]\n",
        "print(\"Selected sample indices for reconstruction:\", selected_indices)\n",
        "selected_samples = [dataset[i] for i in selected_indices]\n",
        "selected_states = torch.stack([s for s, l in selected_samples])\n",
        "selected_labels = torch.tensor([l for s, l in selected_samples], dtype=torch.long)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0IUe5fBFyTQ6",
        "outputId": "822c743c-d962-4320-8032-1c1e6a6c0ca0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Building index for lazy dataset...\n",
            "Indexing file: /content/drive/MyDrive/data/carracingv3.pkl\n",
            "Indexing file: /content/drive/MyDrive/data/airraid.pkl\n",
            "Indexing file: /content/drive/MyDrive/data/pinpong.pkl\n",
            "Total samples indexed: 141513\n",
            "Selected sample indices for reconstruction: [96413, 0, 48330]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "latent_dim = 128\n",
        "num_classes = 3"
      ],
      "metadata": {
        "id": "WwwyH8lAyUp7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class CVAE(nn.Module):\n",
        "    def __init__(self, latent_dim, num_classes):\n",
        "        super(CVAE, self).__init__()\n",
        "        self.num_classes = num_classes\n",
        "        self.encoder = nn.Sequential(\n",
        "            nn.Conv2d(3 + num_classes, 32, kernel_size=4, stride=2, padding=1),  # -> [32, 32, 32]\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(32, 64, kernel_size=4, stride=2, padding=1),               # -> [64, 16, 16]\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(64, 128, kernel_size=4, stride=2, padding=1),              # -> [128, 8, 8]\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(128, 256, kernel_size=4, stride=2, padding=1),             # -> [256, 4, 4]\n",
        "            nn.ReLU()\n",
        "        )\n",
        "        self.fc_mu = nn.Linear(256 * 4 * 4, latent_dim)\n",
        "        self.fc_logvar = nn.Linear(256 * 4 * 4, latent_dim)\n",
        "        self.fc_decode = nn.Linear(latent_dim + num_classes, 256 * 4 * 4)\n",
        "        self.decoder = nn.Sequential(\n",
        "            nn.ConvTranspose2d(256, 128, kernel_size=4, stride=2, padding=1),    # -> [128, 8, 8]\n",
        "            nn.ReLU(),\n",
        "            nn.ConvTranspose2d(128, 64, kernel_size=4, stride=2, padding=1),     # -> [64, 16, 16]\n",
        "            nn.ReLU(),\n",
        "            nn.ConvTranspose2d(64, 32, kernel_size=4, stride=2, padding=1),      # -> [32, 32, 32]\n",
        "            nn.ReLU(),\n",
        "            nn.ConvTranspose2d(32, 3, kernel_size=4, stride=2, padding=1),       # -> [3, 64, 64]\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "    def encode(self, x, label):\n",
        "        one_hot = torch.nn.functional.one_hot(label, num_classes=self.num_classes).float()\n",
        "        one_hot = one_hot.unsqueeze(2).unsqueeze(3).expand(-1, -1, x.size(2), x.size(3))\n",
        "        x = torch.cat([x, one_hot], dim=1)\n",
        "        x = self.encoder(x)\n",
        "        x = x.view(x.size(0), -1)\n",
        "        mu = self.fc_mu(x)\n",
        "        logvar = self.fc_logvar(x)\n",
        "        return mu, logvar\n",
        "\n",
        "    def reparameterize(self, mu, logvar):\n",
        "        std = torch.exp(0.5 * logvar)\n",
        "        eps = torch.randn_like(std)\n",
        "        return mu + std * eps\n",
        "\n",
        "    def decode(self, z, label):\n",
        "        one_hot = torch.nn.functional.one_hot(label, num_classes=self.num_classes).float()\n",
        "        z = torch.cat([z, one_hot], dim=1)\n",
        "        x = self.fc_decode(z)\n",
        "        x = x.view(-1, 256, 4, 4)\n",
        "        x = self.decoder(x)\n",
        "        return x\n",
        "\n",
        "    def forward(self, x, label):\n",
        "        mu, logvar = self.encode(x, label)\n",
        "        z = self.reparameterize(mu, logvar)\n",
        "        x_recon = self.decode(z, label)\n",
        "        return x_recon, mu, logvar"
      ],
      "metadata": {
        "id": "UrCmuke1yVy7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = CVAE(latent_dim, num_classes).to(device)\n",
        "optimizer = optim.Adam(model.parameters(), lr=1e-3)"
      ],
      "metadata": {
        "id": "rnKQ_C_FyXJz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def loss_function(recon_x, x, mu, logvar):\n",
        "    BCE = nn.functional.binary_cross_entropy(recon_x, x, reduction='sum')\n",
        "    KLD = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp())\n",
        "    total_loss = BCE + KLD\n",
        "    return total_loss, BCE, KLD\n",
        "\n",
        "\n",
        "epochs = 80\n",
        "loss_list = []\n",
        "bce_list = []\n",
        "kld_list = []\n",
        "model.train()\n",
        "\n",
        "for epoch in range(1, epochs + 1):\n",
        "    train_loss = 0\n",
        "    total_bce = 0\n",
        "    total_kld = 0\n",
        "    for states_batch, labels_batch in dataloader:\n",
        "        states_batch = states_batch.to(device)\n",
        "        labels_batch = labels_batch.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        recon_batch, mu, logvar = model(states_batch, labels_batch)\n",
        "        loss, bce_loss, kld_loss = loss_function(recon_batch, states_batch, mu, logvar)\n",
        "        loss.backward()\n",
        "        train_loss += loss.item()\n",
        "        total_bce += bce_loss.item()\n",
        "        total_kld += kld_loss.item()\n",
        "        optimizer.step()\n",
        "\n",
        "    avg_loss = train_loss / len(dataset)\n",
        "    avg_bce = total_bce / len(dataset)\n",
        "    avg_kld = total_kld / len(dataset)\n",
        "    loss_list.append(avg_loss)\n",
        "    bce_list.append(avg_bce)\n",
        "    kld_list.append(avg_kld)\n",
        "    print(f\"Epoch {epoch}, Avg Total Loss: {avg_loss:.4f}, BCE: {avg_bce:.4f}, KLD: {avg_kld:.4f}\")\n",
        "\n",
        "\n",
        "    if epoch % 10 == 0:\n",
        "        model.eval()\n",
        "        with torch.no_grad():\n",
        "            states_tensor = selected_states.to(device)\n",
        "            labels_tensor = selected_labels.to(device)\n",
        "            recon, _, _ = model(states_tensor, labels_tensor)\n",
        "            for i in range(len(selected_labels)):\n",
        "\n",
        "                original = selected_states[i].permute(1, 2, 0).cpu().numpy()\n",
        "                reconstructed = recon[i].permute(1, 2, 0).cpu().numpy()\n",
        "                plt.figure(figsize=(10, 5))\n",
        "                plt.subplot(1, 2, 1)\n",
        "                plt.imshow(original.astype(np.float32))\n",
        "                plt.title(f\"Original - Game {selected_labels[i].item()}\")\n",
        "                plt.axis('off')\n",
        "                plt.subplot(1, 2, 2)\n",
        "                plt.imshow(reconstructed.astype(np.float32))\n",
        "                plt.title(f\"Reconstructed - Epoch {epoch}\")\n",
        "                plt.axis('off')\n",
        "                plt.savefig(f\"/content/drive/MyDrive/recon_epoch_{epoch}_game_{selected_labels[i].item()}.png\")\n",
        "                plt.close()\n",
        "        model.train()\n",
        "\n",
        "\n",
        "    if epoch % 10 == 0:\n",
        "        save_path = f\"/content/drive/MyDrive/general_CVAE_epoch_{epoch}.pth\"\n",
        "        torch.save(model.state_dict(), save_path)\n",
        "        print(f\"Model saved at epoch {epoch}!\")\n",
        "\n",
        "\n",
        "torch.save(model.state_dict(), \"/content/drive/MyDrive/general_CVAE.pth\")\n",
        "print(\"Model saved at the end of training!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "KWv8DZjrzYYr",
        "outputId": "ab8b24e1-4cbe-47f8-a4fa-0bf60e124b6d"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'model' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-2666018b8764>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mbce_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mkld_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(12, 6))\n",
        "plt.plot(range(1, epochs + 1), loss_list, label='Total Loss')\n",
        "plt.plot(range(1, epochs + 1), bce_list, label='BCE Loss')\n",
        "plt.plot(range(1, epochs + 1), kld_list, label='KLD Loss')\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Average Loss\")\n",
        "plt.title(\"Training Losses over Epochs\")\n",
        "plt.legend()\n",
        "plt.savefig(\"/content/drive/MyDrive/loss_plot.png\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "kyGhnuxH4r1C"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}